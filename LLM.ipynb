{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTOWm6aJz_PT"
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install transformers sentence-transformers faiss-cpu gradio\n",
        "!pip install scikit-learn pandas numpy\n",
        "!pip install swarm  # If unavailable, will give fallback later\n",
        "!pip install langchain\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYqbEgh3vv1O"
      },
      "outputs": [],
      "source": [
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwpIym5W0Mx8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# Define sample queries for each intent\n",
        "data = pd.read_csv(\"/content/all_tickets_processed_improved_v3.csv\")\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Generate duplicates with slight modifications to expand dataset size to ~600 rows\n",
        "def augment_text(text):\n",
        "    # simple augment by rephrasing with synonyms, you can expand later\n",
        "    replacements = {\n",
        "        \"How do I\": \"What is the way to\",\n",
        "        \"My\": \"The\",\n",
        "        \"How to\": \"What is the method to\",\n",
        "        \"Where can I\": \"Where do I\",\n",
        "        \"Can I\": \"Is it possible to\"\n",
        "    }\n",
        "    for k, v in replacements.items():\n",
        "        if text.startswith(k):\n",
        "            return text.replace(k, v)\n",
        "    return text\n",
        "\n",
        "augmented_rows = []\n",
        "for i in range(40):  # multiply data by 40 (15*40 = 600)\n",
        "    for _, row in df.iterrows():\n",
        "        new_text = augment_text(row['Document']) # Use 'summary' column\n",
        "        augmented_rows.append({'summary': new_text, 'category': row['Topic_group']})\n",
        "\n",
        "df_augmented = pd.DataFrame(augmented_rows)\n",
        "\n",
        "# Shuffle the dataset\n",
        "df_augmented = df_augmented.sample(frac=1).reset_index(drop=True)\n",
        "df_augmented.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dx12GnI70YcY"
      },
      "outputs": [],
      "source": [
        "knowledge_base = [\n",
        "    {\n",
        "        \"title\": \"Laptop Reset Policy\",\n",
        "        \"content\": \"To reset your company laptop, press F11 during boot and follow the on-screen instructions. Ensure backup is taken before reset.\"\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"Password Reset Guide\",\n",
        "        \"content\": \"Employees can reset passwords via the internal portal under Account Settings > Password Reset. For two-factor issues, contact IT support.\"\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"HR Leave Policy\",\n",
        "        \"content\": \"Full-time employees are entitled to 20 paid leave days per year. Submit requests on the HR portal at least 3 days in advance.\"\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"Software Installation Request\",\n",
        "        \"content\": \"Employees must raise a ticket through ServiceNow to request software installation. Licensing approval from the manager is required.\"\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"Email Configuration\",\n",
        "        \"content\": \"To configure company email on mobile, use Exchange settings with domain 'corp.company.com'. VPN must be active.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Convert to DataFrame\n",
        "kb_df = pd.DataFrame(knowledge_base)\n",
        "kb_df.to_csv(\"knowledge_base.csv\", index=False)\n",
        "\n",
        "# View\n",
        "kb_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsHB39sw5tCq"
      },
      "outputs": [],
      "source": [
        "!pip install langchain faiss-cpu\n",
        "!pip install sentence-transformers\n",
        "!pip install huggingface_hub\n",
        "!pip install langchain-community # Ensure community package is installed here as well\n",
        "\n",
        "# For T5 generation\n",
        "!pip install transformers\n",
        "\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.document_loaders import DataFrameLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "\n",
        "from transformers import pipeline\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLb1HSYN5yJT"
      },
      "outputs": [],
      "source": [
        "# Load the knowledge base\n",
        "kb_df = pd.read_csv(\"knowledge_base.csv\")\n",
        "\n",
        "# Use LangChain DataFrameLoader\n",
        "loader = DataFrameLoader(kb_df, page_content_column=\"content\")\n",
        "documents = loader.load()\n",
        "\n",
        "# Split text (optional here since docs are short)\n",
        "splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "docs = splitter.split_documents(documents)\n",
        "\n",
        "# Use SentenceTransformer for embedding\n",
        "embed_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "# Create FAISS vector store\n",
        "vectorstore = FAISS.from_documents(docs, embed_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfRp71zU6aBK"
      },
      "outputs": [],
      "source": [
        "# Set up text2text-generation pipeline using T5\n",
        "qa_pipeline = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\", max_length=256)\n",
        "\n",
        "# Wrap it in LangChain\n",
        "llm = HuggingFacePipeline(pipeline=qa_pipeline)\n",
        "\n",
        "# Build RetrievalQA chain\n",
        "rag_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 3}),\n",
        "    return_source_documents=True\n",
        ")\n",
        "\n",
        "# Example Query Test\n",
        "query = \"How do I reset my company laptop?\"\n",
        "result = rag_chain(query)\n",
        "\n",
        "print(\"Answer:\", result[\"result\"])\n",
        "print(\"\\nRetrieved Docs:\")\n",
        "for doc in result['source_documents']:\n",
        "    print(\"â€”\", doc.page_content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_i_WSv5G6fG7"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets scikit-learn\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.optim import AdamW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdxOY_VT7A95"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "\n",
        "data = pd.read_csv(\"/content/all_tickets_processed_improved_v3.csv\")\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Optional: augment synthetic data to increase size\n",
        "def augment_text(text):\n",
        "    replacements = {\n",
        "        \"How do I\": \"What is the way to\",\n",
        "        \"My\": \"The\",\n",
        "        \"How to\": \"What is the method to\",\n",
        "        \"Where can I\": \"Where do I\",\n",
        "        \"Can I\": \"Is it possible to\"\n",
        "    }\n",
        "    for k, v in replacements.items():\n",
        "        if text.startswith(k):\n",
        "            return text.replace(k, v)\n",
        "    return text\n",
        "\n",
        "augmented_rows = []\n",
        "for _ in range(40):  # replicate and augment ~40 times to get bigger dataset\n",
        "    for _, row in df.iterrows():\n",
        "        augmented_rows.append({'summary': augment_text(row['Document']), 'category': row['Topic_group']})\n",
        "\n",
        "df_aug = pd.DataFrame(augmented_rows).sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "df_aug['label'] = le.fit_transform(df_aug['category'])\n",
        "\n",
        "# Split\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    df_aug['summary'].tolist(), df_aug['label'].tolist(), test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Dataset class\n",
        "class IntentDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=64)\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'input_ids': torch.tensor(self.encodings['input_ids'][idx]),\n",
        "            'attention_mask': torch.tensor(self.encodings['attention_mask'][idx]),\n",
        "            'labels': torch.tensor(self.labels[idx])\n",
        "        }\n",
        "\n",
        "train_dataset = IntentDataset(train_texts, train_labels)\n",
        "val_dataset = IntentDataset(val_texts, val_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUL0_OEr7hIL"
      },
      "outputs": [],
      "source": [
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(le.classes_))\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(3):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "    print(f\"Epoch {epoch+1} Loss: {total_loss/len(train_loader):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJVT5rPI7mhq"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "predictions, true_labels = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        preds = torch.argmax(outputs.logits, dim=1)\n",
        "        predictions.extend(preds.cpu().numpy())\n",
        "        true_labels.extend(batch['labels'].cpu().numpy())\n",
        "\n",
        "print(classification_report(true_labels, predictions, target_names=le.classes_))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDvYJl_vzJJP"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained(\"bert_intent_classifier\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mAbjqcY7qX2"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "good_responses = [\n",
        "    \"To reset your laptop, hold the power button for 10 seconds and restart.\",\n",
        "    \"Please contact HR at hr@company.com for leave policy clarification.\",\n",
        "    \"You can access your payslip via the Employee Portal under Payroll section.\",\n",
        "    \"Follow the steps in the IT manual page 42 for VPN configuration.\",\n",
        "    \"Weâ€™ve escalated the issue to the technical team. Youâ€™ll hear back soon.\"\n",
        "]\n",
        "\n",
        "bad_responses = [\n",
        "    \"idk maybe try restarting it lol\",\n",
        "    \"Check somewhere else for info\",\n",
        "    \"What even is VPN?\",\n",
        "    \"You should probably read the manual or something.\",\n",
        "    \"Leave stuff? Ask someone in HR I guess.\"\n",
        "]\n",
        "\n",
        "# Duplicate and label\n",
        "synthetic_texts = good_responses * 20 + bad_responses * 20\n",
        "synthetic_labels = [1]*len(good_responses)*20 + [0]*len(bad_responses)*20  # 1=Good, 0=Bad\n",
        "\n",
        "# Shuffle\n",
        "combined = list(zip(synthetic_texts, synthetic_labels))\n",
        "random.shuffle(combined)\n",
        "texts, labels = zip(*combined)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F71w9pBvCNUP"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    list(texts), list(labels), test_size=0.2, random_state=42)\n",
        "\n",
        "class ResponseDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=64)\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'input_ids': torch.tensor(self.encodings['input_ids'][idx]),\n",
        "            'attention_mask': torch.tensor(self.encodings['attention_mask'][idx]),\n",
        "            'labels': torch.tensor(self.labels[idx])\n",
        "        }\n",
        "\n",
        "train_dataset = ResponseDataset(train_texts, train_labels)\n",
        "val_dataset = ResponseDataset(val_texts, val_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HkCAHOnCQio"
      },
      "outputs": [],
      "source": [
        "refiner_model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "refiner_model.to(device)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8)\n",
        "\n",
        "optimizer = AdamW(refiner_model.parameters(), lr=3e-5)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(3):\n",
        "    refiner_model.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = refiner_model(**batch)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "    print(f\"[Refiner] Epoch {epoch+1} Loss: {total_loss/len(train_loader):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZ23hpgeCTaU"
      },
      "outputs": [],
      "source": [
        "refiner_model.eval()\n",
        "refiner_preds, refiner_true = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = refiner_model(**batch)\n",
        "        preds = torch.argmax(outputs.logits, dim=1)\n",
        "        refiner_preds.extend(preds.cpu().numpy())\n",
        "        refiner_true.extend(batch['labels'].cpu().numpy())\n",
        "\n",
        "print(classification_report(refiner_true, refiner_preds, target_names=[\"Needs Improvement\", \"Good\"]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLPBTBykCXDg"
      },
      "outputs": [],
      "source": [
        "class RouterAgent:\n",
        "    def __init__(self, model, tokenizer, label_map):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.label_map = label_map\n",
        "        self.model.eval()\n",
        "\n",
        "    def route(self, query):\n",
        "        inputs = self.tokenizer(query, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
        "        with torch.no_grad():\n",
        "            logits = self.model(**inputs).logits\n",
        "        predicted_class = torch.argmax(logits, dim=1).item()\n",
        "        return self.label_map[predicted_class]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IXFj7L7DYmb"
      },
      "outputs": [],
      "source": [
        "label_map = {0: \"IT\", 1: \"HR\", 2: \"Product\"}  # based on your classifier's training\n",
        "router_agent = RouterAgent(model, tokenizer, label_map)\n",
        "router_agent.route(\"How can I access my salary slip?\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iealj_G4CbE2"
      },
      "outputs": [],
      "source": [
        "class ResponseRefinerAgent:\n",
        "    def __init__(self, model, tokenizer):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.model.eval()\n",
        "\n",
        "    def refine(self, response):\n",
        "        inputs = self.tokenizer(response, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
        "        with torch.no_grad():\n",
        "            logits = self.model(**inputs).logits\n",
        "        prediction = torch.argmax(logits, dim=1).item()\n",
        "        return \"Acceptable\" if prediction == 1 else \"Needs Improvement\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CrXg5-1WDc8P"
      },
      "outputs": [],
      "source": [
        "refiner_agent = ResponseRefinerAgent(refiner_model, tokenizer)\n",
        "refiner_agent.refine(\"Please turn off your laptop and contact IT.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpKJMi3KCf18"
      },
      "outputs": [],
      "source": [
        "!pip install langchain faiss-cpu sentence-transformers transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMW87b_1CiuI"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.docstore.document import Document\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Sample documents\n",
        "kb_texts = [\n",
        "    \"To reset your laptop, press and hold the power button for 10 seconds.\",\n",
        "    \"To apply for leave, log in to the HR portal and click on 'Apply Leave'.\",\n",
        "    \"Access the company VPN using your employee credentials on the VPN client.\",\n",
        "    \"Payslips are available in the Payroll section of the Employee Portal.\",\n",
        "    \"For hardware issues, contact IT at support@company.com.\"\n",
        "]\n",
        "\n",
        "documents = [Document(page_content=text) for text in kb_texts]\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "vectorstore = FAISS.from_documents(documents, embedding_model)\n",
        "retriever = vectorstore.as_retriever(search_type=\"similarity\", k=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SObbUE3CClKN"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import HuggingFacePipeline\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer, pipeline\n",
        "\n",
        "t5_model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "t5_tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "\n",
        "t5_pipe = pipeline(\"text2text-generation\", model=t5_model, tokenizer=t5_tokenizer)\n",
        "generator = HuggingFacePipeline(pipeline=t5_pipe)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-iabkibDCnVW"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "rag_chain = RetrievalQA.from_chain_type(\n",
        "    llm=generator,\n",
        "    retriever=retriever,\n",
        "    return_source_documents=False\n",
        ")\n",
        "\n",
        "def retrieve_and_generate(query):\n",
        "    return rag_chain.run(query)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "weNh2x_hDh-N"
      },
      "outputs": [],
      "source": [
        "response = retrieve_and_generate(\"How do I access my payslip?\")\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjVrcvWXCrKn"
      },
      "outputs": [],
      "source": [
        "class HelpdeskOrchestrator:\n",
        "    def __init__(self, router_agent, rag_chain, refiner_agent):\n",
        "        self.router = router_agent\n",
        "        self.rag = rag_chain\n",
        "        self.refiner = refiner_agent\n",
        "\n",
        "    def handle_query(self, query):\n",
        "        print(f\"\\nðŸ§­ [Router] Classifying intent...\")\n",
        "        intent = self.router.route(query)\n",
        "        print(f\"âœ… Detected intent: {intent}\\n\")\n",
        "\n",
        "        print(\"ðŸ“š [Knowledge Specialist] Generating response...\")\n",
        "        response = self.rag.run(query)\n",
        "        print(f\"ðŸ’¬ Response:\\n{response}\\n\")\n",
        "\n",
        "        print(\"ðŸ§ª [Response Refiner] Evaluating quality...\")\n",
        "        evaluation = self.refiner.refine(response)\n",
        "        print(f\"ðŸ”Ž Response Quality: {evaluation}\\n\")\n",
        "\n",
        "        return {\n",
        "            \"intent\": intent,\n",
        "            \"response\": response,\n",
        "            \"evaluation\": evaluation\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHAV4R8zDBYY"
      },
      "outputs": [],
      "source": [
        "orchestrator = HelpdeskOrchestrator(router_agent, rag_chain, refiner_agent)\n",
        "\n",
        "query = \"How do I apply for medical leave?\"\n",
        "output = orchestrator.handle_query(query)\n",
        "\n",
        "print(\"Final Output:\", output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAE1h3QtDqd7"
      },
      "outputs": [],
      "source": [
        "!pip install gradio\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "def interactive_helpdesk(query):\n",
        "    result = orchestrator.handle_query(query)\n",
        "    return f\"\"\"ðŸ”¹ Intent: {result['intent']}\n",
        "\n",
        "ðŸ’¬ Response:\n",
        "{result['response']}\n",
        "\n",
        "ðŸ§ª Evaluation: {result['evaluation']}\n",
        "\"\"\"\n",
        "\n",
        "gr.Interface(fn=interactive_helpdesk, inputs=\"text\", outputs=\"text\", title=\"ðŸ§  Swarm-Powered Enterprise Helpdesk\").launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VhM67EadDqae"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}